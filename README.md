# ğŸ§  Next Word Generator using LSTM  
A deep learning project that predicts the next word in a sentence using an LSTM-based neural network.  
This project demonstrates text preprocessing, tokenization, sequence generation, model training, and text prediction using TensorFlow/Keras.


## ğŸš€ Project Overview
The goal of this project is to build a language model capable of generating the next probable word based on historical sequence data.  
We use:
- Recurrent Neural Networks (RNN)
- Long Short Term Memory (LSTM) architecture
- Tokenization + Padding
- Categorical Crossentropy Loss
- Adam Optimizer

## ğŸ“‚ Dataset
You can use any text dataset such as:
- Articles  
- Stories  
- Song Lyrics  
- Custom text files  

Make sure your text dataset is cleaned (lowercase, no special characters unless needed).


## ğŸ› ï¸ Tech Stack
- Python  
- TensorFlow / Keras  
- NumPy  
- Jupyter Notebook  


## ğŸ“Œ Project Workflow
1. Load and clean dataset  
2. Tokenize text and create sequences  
3. Convert sequences into predictors (`X`) and labels (`y`)  
4. Build LSTM-based model  
5. Train and evaluate model  
6. Predict the next word  


